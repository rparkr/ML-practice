{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "# Lab 2: Intro to PyTorch\n",
        "\n",
        "## Deliverable\n",
        "\n",
        "For this lab, you will submit an IPython notebook via Learning Suite.\n",
        "This lab will be mostly boilerplate code, but you will be required to implement a few extras.\n",
        "\n",
        "**NOTE: you almost certainly will not understand most of what's going on in this lab!\n",
        "That's ok - the point is just to get you going with PyTorch.\n",
        "We'll be working on developing a deeper understanding of every part of this code\n",
        "over the course of the next two weeks.**\n",
        "\n",
        "A major goal of this lab is to help you become conversant in working through PyTorch\n",
        "tutorials and documentation.\n",
        "You should turn to the documentation first, but you may google whatever you need, as there are many great PyTorch tutorials online.\n",
        "\n",
        "This notebook will have four parts:\n",
        "\n",
        "* Part 1: Your notebook should contain the boilerplate code. See below.\n",
        "\n",
        "* Part 2: Your notebook should contain a testing loop.\n",
        "\n",
        "* Part 3: Your notebook should contain a visualization of test/training performance over time.\n",
        "\n",
        "The resulting image could, for example, look like this:\n",
        "![example image](http://liftothers.org/dokuwiki/lib/exe/fetch.php?cache=&w=900&h=608&tok=3092fe&media=cs501r_f2018:lab2.png)\n",
        "\n",
        "* Part 4: Your notebook should contain the completed microtasks and pass all the asserts.\n",
        "\n",
        "See the assigned readings for pointers to documentation on PyTorch.\n",
        "___\n",
        "\n",
        "### Grading standards:\n",
        "Your notebook will be graded on the following:\n",
        "\n",
        "* 40% Successfully followed lab video and typed in code\n",
        "* 20% Modified code to include a test/train split\n",
        "* 20% Modified code to include a visualization of train/test losses\n",
        "* 10% Tidy and legible figures, including labeled axes where appropriate\n",
        "* 10% Correct solutions to the microtasks\n",
        "___\n",
        "\n",
        "### Description\n",
        "Throughout this class, we will be using PyTorch to implement our deep neural networks. \n",
        "PyTorch is a deep learning framework that handles the low-level details of \n",
        "GPU integration and automatic differentiation.\n",
        "\n",
        "The goal of this lab is to help you become familiar with PyTorch. \n",
        "The four parts of the lab are outlined above.\n",
        "\n",
        "For part 1, you should watch the video below, and type in the code as it is explained to you.\n",
        "\n",
        "A more detailed outline of Part 1 is below.\n",
        "\n",
        "For part 2, you must add a validation (or testing) loop using the \n",
        "FashionMNIST dataset with train=False\n",
        "\n",
        "For part 3, you must plot the loss values.\n",
        "\n",
        "For part 4, you must complete the microtasks and pass all asserts.\n",
        "\n",
        "Optional: Demonstrate overfitting on the training data.\n",
        "\n",
        "The easiest way to do this is to limit the size of your training dataset \n",
        "so that it only returns a single batch (i.e. len(dataloader) == batch_size, \n",
        "and train for multiple epochs. For example,\n",
        "I set my batch size to 42, and augmented my dataloader to produce only 42 \n",
        "unique items by overwriting the len function to return 42. \n",
        "In my training loop, I performed a validation every epoch which basically corresponded \n",
        "to a validation every step.\n",
        "\n",
        "In practice, you will normally compute your validation loss every n steps, \n",
        "rather than at the end of every epoch. This is because some epochs can take hours, \n",
        "or even days and you don’t often want to wait that long to see your results.\n",
        "\n",
        "Testing your algorithm by using a single batch and training until overfitting \n",
        "is a great way of making sure that your model and optimizer are working the way they should!\n",
        "\n",
        "___\n",
        "\n",
        "### Part 0\n",
        "Watch Tutorial Video\n",
        "\n",
        "[https://youtu.be/E76hLX9WCLE](https://youtu.be/E76hLX9WCLE)\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* ✔ Watch Tutorial Video\n",
        "\n",
        "### Part 1\n",
        "Your notebook should contain the boilerplate code. See below.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* ✔ Replicate boilerplate from the video\n",
        "\n",
        "___\n",
        "\n",
        "### Part 2\n",
        "Your notebook should contain a testing (validation) loop.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* ✔ Add a testing (validation) loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QClXc9i7VRyA",
        "outputId": "98d3eab8-0759-4720-e8ef-0b5f4bd882b6",
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch \n",
        "!pip install torchvision\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDxkBvA0H22n"
      },
      "source": [
        "# Note to TAs\n",
        "To help me process and understand the video so I can best retain the information (and use it for reference later), I included a _ton_ of comments in my code below. \n",
        "\n",
        "I recognize that so many comments reduces simplicity in readability; thanks for your understanding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU80yuvqVXwk",
        "outputId": "b4b12990-b81f-4b9d-ab12-bad1bbeec5a5",
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch: 99, batch: 1199, loss: 0.6827, val_loss: 0.6596:   0%|          | 0/120000 [18:12<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "# ===============================================\n",
        "# Write the boilerplate code from the video here\n",
        "# ===============================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# See: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "# tqdm creates a progress bar. See: https://github.com/tqdm/tqdm#readme\n",
        "# See also: https://tqdm.github.io/\n",
        "from tqdm import tqdm\n",
        "\n",
        "# You need to request a GPU from Runtime > Change Runtime Type\n",
        "assert torch.cuda.is_available()\n",
        "\n",
        "# ===============================================\n",
        "# Extend the torch.Module class to create your own neural network\n",
        "# ===============================================\n",
        "\n",
        "# See: https://pytorch.org/docs/stable/notes/extending.html#extending-torch-nn\n",
        "# Create the neural network model, which holds parameters and gradients\n",
        "# In PyTorch, all models inherit from the torch.nn.Module class\n",
        "class LinearNetwork(nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        # Call the superclass, to get parameters from the class that this belongs to\n",
        "        super(LinearNetwork, self).__init__()\n",
        "        x, y = dataset[0]\n",
        "        # Since we're working with images, call the torch function .size() to get the dimensions\n",
        "        channels, height, width = x.size()\n",
        "        # There are 10 possible classes this network predicts\n",
        "        out_dimensions = 10\n",
        "\n",
        "        # Create the network. nn.Sequential() is a class that can hold all \n",
        "        # other modules within it, in a hierarchy. It cascades methods down\n",
        "        # such that the output of one becomes the input to the next.\n",
        "        # nn.Linear is a fully-connected layer.\n",
        "        # The first argument for each layer is the number of inputs.\n",
        "        # The second argument for each layer is the number of outputs.\n",
        "        # The output number for one layer should be the same as the input number\n",
        "        # for the layer that follows it.\n",
        "        output_number = 1000\n",
        "        input_number = output_number\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(channels * height * width, output_number), \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(input_number, out_dimensions)\n",
        "        )\n",
        "\n",
        "    # Pass data forward through the network, as a batch\n",
        "    def forward(self, x):\n",
        "        batch_num, channels, height, width = x.size()\n",
        "        # Flatten data into a 2-dimensional matrix so it can be passed\n",
        "        # through the Linear layers (comes in as a 4-D matrix, because of batch count)\n",
        "        flattened = x.view(batch_num, channels * height * width)\n",
        "        return self.net(flattened)\n",
        "\n",
        "    # DON'T OVERWRITE THE backward() FUNCTION -- it calculates the gradient\n",
        "\n",
        "# ===============================================\n",
        "# Create a dataset class that extends the torch.utils.data Dataset class here\n",
        "# ===============================================\n",
        "\n",
        "# See: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "# Create a dataset loader, inheriting from the torch.utils.data.Dataset class\n",
        "class FashionMNISTProcessedDataset(Dataset):\n",
        "    # root is the directory to save in\n",
        "    def __init__(self, root, train=True):\n",
        "        # See: https://pytorch.org/vision/stable/datasets.html#fashion-mnist\n",
        "        self.data = datasets.FashionMNIST(\n",
        "            root,\n",
        "            train=True,\n",
        "            transform = transforms.ToTensor(),\n",
        "            download=True)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        x, y = self.data[i]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "# ===============================================\n",
        "# Instantiate the train and validation datasets\n",
        "# ===============================================\n",
        "train_dataset = FashionMNISTProcessedDataset(root='/tmp/fashionmnist', train=True)\n",
        "val_dataset = FashionMNISTProcessedDataset(root='/tmp/fashionmnist', train=False)\n",
        "\n",
        "# ===============================================\n",
        "# Instantiate your data loaders\n",
        "# Create batches from the training and validation datasets\n",
        "# ===============================================\n",
        "train_loader = DataLoader(train_dataset, batch_size=50, pin_memory=True)\n",
        "validation_loader = DataLoader(val_dataset, batch_size=50)\n",
        "\n",
        "# ===============================================\n",
        "# Instantiate your model, loss, and optimizer functions\n",
        "# ===============================================\n",
        "model = LinearNetwork(train_dataset)\n",
        "model = model.cuda()\n",
        "# Set cost (loss) function to Cross Entropy Loss\n",
        "objective = torch.nn.CrossEntropyLoss()\n",
        "# The optimizer minimizes the cost function\n",
        "optimizer = optim.SGD(params=model.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "# ===============================================\n",
        "# Run your training / validation loops\n",
        "# ===============================================\n",
        "\n",
        "# An epoch ends when all batches of training data have been processed\n",
        "num_epochs = 100\n",
        "loop = tqdm(total=len(train_loader) * num_epochs, position=0)\n",
        "\n",
        "# Initialize variables for validation\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "counter = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    batch = 0\n",
        "    for x, y_truth in train_loader:\n",
        "        # load tensors on GPU (non_blocking=True means \"don't wait until all data has moved from CPU to GPU\")\n",
        "        x, y_truth = x.cuda(non_blocking=True), y_truth.cuda(non_blocking=True)\n",
        "        # Clear the optimizer gradient so it can be updated\n",
        "        optimizer.zero_grad()\n",
        "        # Predicted values are y_hat\n",
        "        y_hat = model(x)\n",
        "        # Determine the loss\n",
        "        loss = objective(y_hat, y_truth)\n",
        "\n",
        "        # Validate every on the first batch every 5 epochs\n",
        "        if (epoch % 5 == 0) and batch == 0:\n",
        "            train_losses.append(loss.item())\n",
        "            validation_loss_list = []\n",
        "            # Validation loop (same as training loop, but w/ validation data)\n",
        "            for val_x, val_y_truth in validation_loader:\n",
        "                val_x, val_y_truth = val_x.cuda(non_blocking=True), val_y_truth.cuda(non_blocking=True)\n",
        "                val_y_hat = model(val_x)\n",
        "                validation_loss_list.append(objective(val_y_hat, val_y_truth).item())\n",
        "            # Save the average of the loss\n",
        "            validation_losses.append(sum(validation_loss_list) / float(len(validation_loss_list)))\n",
        "        loop.set_description(f'epoch: {epoch}'\n",
        "                            f', batch: {batch:d}'\n",
        "                            f', loss: {loss.item():.4f}'\n",
        "                            f', val_loss: {validation_losses[-1]:.4f}')\n",
        "        # Compute the gradient on each level of the model (network)\n",
        "        loss.backward()\n",
        "\n",
        "        # Take a step to decrease the cost (loss) function\n",
        "        optimizer.step()\n",
        "        batch += 1\n",
        "\n",
        "# End training, hide output display\n",
        "loop.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgjxN5aDZ9sD",
        "outputId": "f45ba124-9be5-416d-a86a-26eb7bf6af18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 795,010\n"
          ]
        }
      ],
      "source": [
        "# View the number of parameters\n",
        "# torch.numel = number of elements\n",
        "num_params = sum([torch.numel(layer) for layer in model.parameters()])\n",
        "print(f'Total parameters: {num_params:,d}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IZmHOvirnFn"
      },
      "source": [
        "\n",
        "___\n",
        "\n",
        "### Part 3\n",
        "Your notebook should contain a visualization of test/training\n",
        "performance over time. Use matplotlib.pyplot, and label the graph's axes.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Add a visualization of test/train performance (i.e. loss) over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NKHvRKQWaFZ"
      },
      "outputs": [],
      "source": [
        "# View the list of losses calculated every 5 epochs\n",
        "train_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "YqYrbI5-WHb3",
        "outputId": "6c707328-80eb-4cbe-8ba3-c1e018d462fd",
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Write your code to create a plot of your loss over time\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "epoch_count = [5 * item for item in range(len(validation_losses))]\n",
        "ax.plot(epoch_count, validation_losses, label='Validation Loss', c='darkred')\n",
        "ax.plot(epoch_count, train_losses, label='Training Loss', c='royalblue')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Model performance over time: training and validation')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wW4QNYG4LE2"
      },
      "source": [
        "\n",
        "___\n",
        "\n",
        "### Part 4\n",
        "Complete the following microtasks to learn some important PyTorch skills.\n",
        "\n",
        "If you do not know how to complete one of the microtasks, use [PyTorch's documentation](https://pytorch.org/docs/stable/index.html)! PyTorch is very well documented, and you will need to learn how to use the documentation, especially in later labs.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Complete microtasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEMHUksuCYh6"
      },
      "source": [
        "### Computation Graph Microtasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8jriPb-CYh8",
        "outputId": "39617bcc-df7c-4fe3-9c90-462a32aa2972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.8713, 0.0704, 0.3029, 0.9503, 0.5776, 0.2419, 0.5028, 0.9189, 0.9371,\n",
            "        0.0245])\n"
          ]
        }
      ],
      "source": [
        "# To understand how PyTorch organizes the computation graph, let's walk through \n",
        "# a quick example!\n",
        "\n",
        "# 1. First, construct a tensor 'a' that contains 10 random floats. \n",
        "# This will simulate the output layer of a network. Hint: use `torch.rand`.\n",
        "a = torch.rand(10)\n",
        "print(a)\n",
        "assert a.size() == torch.Size([10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsODlPlICYh-",
        "outputId": "cc68155f-9e86-4ff1-c37d-d35a436ccb0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([0.8713, 0.0704, 0.3029, 0.9503, 0.5776, 0.2419, 0.5028, 0.9189, 0.9371,\n",
            "        0.0245], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# 2. Now turn 'a' into an `nn.Parameter` so that it be attached to the computation\n",
        "# graph.\n",
        "\n",
        "a = nn.Parameter(data=a)\n",
        "print(a)\n",
        "assert type(a) == nn.Parameter\n",
        "\n",
        "# Notice that our original tensor 'a' is nested inside of a Parameter object.\n",
        "# The Parameter object knows that it will need to compute gradients at some point.\n",
        "\n",
        "# No need to do anything here, but this assert should pass.\n",
        "assert a.requires_grad == True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pWBd2pGCYiB",
        "outputId": "b5736456-d63c-48c5-8f43-b906d651fd25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.9823, grad_fn=<NllLossBackward0>)\n",
            "tensor([ 0.1313,  0.0590,  0.0744,  0.1421,  0.0979,  0.0700,  0.0909, -0.8622,\n",
            "         0.1403,  0.0563])\n"
          ]
        }
      ],
      "source": [
        "# 3. Let's run 'a' through a loss function. The output of the loss function is\n",
        "# just another tensor, but this tensor remembers what operations produced it.\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss = loss_fn(a.unsqueeze(0), torch.Tensor([7]).long())\n",
        "print(loss)\n",
        "\n",
        "# Now, instruct the network to do a backward pass, by calling '.backward()' on the \n",
        "# result of the loss function. We should now be able to see the gradients that \n",
        "# were computed for 'a' w.r.t. the loss.\n",
        "loss.backward()\n",
        "assert a.grad is not None\n",
        "print(a.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWVzQMPnCYiC",
        "outputId": "5e0717d9-dd3b-4cb2-c098-b3fa198272ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([0.8713, 0.0704, 0.3029, 0.9503, 0.5776, 0.2419, 0.5028, 0.9189, 0.9371,\n",
            "        0.0245], requires_grad=True)\n",
            "tensor([0.8713, 0.0704, 0.3029, 0.9503, 0.5776, 0.2419, 0.5028, 0.9189, 0.9371,\n",
            "        0.0245])\n"
          ]
        }
      ],
      "source": [
        "# 4. If we were to use 'a' in another operation, this might affect the computation graph.\n",
        "# To make sure that you are not adversly affecting the computation graph, call\n",
        "# `.detach()` on 'a' and assign the result to a new variable 'b'.\n",
        "b = a.detach()\n",
        "print(a)\n",
        "print(b)\n",
        "assert a.requires_grad == True\n",
        "assert b.requires_grad == False"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CS474_lab2_RyanParker.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
